{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import load_wikipedia_wordvecs\n",
    "from lib.spectral_clustering import similarity_matrix, laplacian_matrix, spectral_clustering\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vecs = load_wikipedia_wordvecs().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(data, s=1):\n",
    "    n = len(data)\n",
    "    scale = [np.sum(np.linalg.norm( data - x.reshape((1, -1)), axis=0)) for x in data ]\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            similarity_matrix[i][j] = s * np.linalg.norm(data[i] - data[j]) / (scale[i]+scale[j])\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codenames = \"penguin,Germany,spy,battery,stadium,opera,shop,ambulance,brush,forest,Mexico,beat,fire,whip,\\\n",
    "switch,horse,band,deck,concert,horn,link,charge,row,line,lock\".split(\",\")\n",
    "indices = np.array([words.index(c) for c in codenames])\n",
    "\n",
    "\n",
    "word_vecs = vecs[indices]\n",
    "\n",
    "s = similarity_matrix(word_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 14\n",
    "assns, (evals, evecs) = spectral_clustering(word_vecs, k=k, lform = \"rw\", metric=\"g\", s=0.5, with_eigen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66553831e-44, -6.29299062e-48, -4.77148844e-50, -1.31014512e-52,\n",
       "       -3.58188440e-53, -4.81077410e-57, -1.79874631e-57,  2.46392021e-61,\n",
       "        2.46392021e-61,  2.46392021e-61,  2.46392021e-61,  2.46392021e-61,\n",
       "        2.46392021e-61,  2.46392021e-61])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 12, 10,  2,  9,  4, 13,  0,  6,  7, 11, 10,  0,  6,  8, 12,  3,\n",
       "        4,  3,  3,  5,  2,  8, 10,  8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spy', 'beat', 'line'],\n",
       " ['opera'],\n",
       " ['stadium'],\n",
       " ['switch', 'lock'],\n",
       " ['ambulance', 'fire'],\n",
       " ['deck'],\n",
       " ['band', 'concert'],\n",
       " ['row'],\n",
       " ['Mexico'],\n",
       " ['shop'],\n",
       " ['horse'],\n",
       " ['penguin', 'Germany', 'forest', 'horn', 'link'],\n",
       " ['brush', 'whip'],\n",
       " ['battery', 'charge']]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[codenames[j] for j in range(len(codenames)) if assns[j] == i] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vec(words, candidates, vocabulary):\n",
    "    # words is a list of word strings\n",
    "    # candidates is a Nx300 dataset of all candidate word vectors\n",
    "    # vocabulary is a list of word strings, 1 per vector in candidate\n",
    "    mean = np.mean([candidates[vocabulary.index(word)] for word in words], axis=0).reshape((1, -1))\n",
    "    diff = np.linalg.norm(candidates - mean, axis=0)\n",
    "    return vocabulary[np.argmin(diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hold'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_vec(('fly', 'Moscow'), vecs, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
